# Wake Word × GPT × Googleカレンダー 音声アシスタント設計・開発フロー（Mac → Raspberry Pi）

---

## 1. ゴール

- Wake Word（Picovoice Porcupine）で音声アシスタントを起動する。
- ChatGPT Realtime API で自然な音声対話を行う。
- 会話の中で「A日のB時にCをリマインドして」と依頼すると、日時と内容を自動抽出する。
- Googleカレンダーへ予定を自動登録する。
- 予定時刻の 10 分前になったら、自動で GPT 音声モードを起動し、音声で通知する。
- 無言状態が一定時間続いた場合、会話セッションを自動終了して、リソース・電力を節約する。

---

## 2. 全体アーキテクチャ

1. ローカルアプリ（Mac / Raspberry Pi）がマイク入力を常時監視する。
2. Porcupine が Wake Word を検出したら、ChatGPT Realtime API との音声対話セッションを開始する。
3. ユーザーの音声入力から LLM が日付・時刻・内容を抽出し、JSON（Function Calling）で表現する。
4. JSON を元に Google カレンダーに予定（Event）を登録する。
5. ローカルアプリがカレンダーを定期的にポーリングして、10分前の予定を検出する。
6. 通知が必要なタイミングになったら、再度 Realtime API を起動し、音声で予定を通知する。
7. 通知後も会話を継続でき、「時間をずらす」「キャンセルする」などの操作を音声で行える。

---

## 3. ステップ別の処理フロー

### 3.1 STEP 1：Wake Word による起動

- 使用技術
  - Picovoice Porcupine（Wake Word 検出）
- 動作概要
  - Porcupine がマイク入力を常時監視（低レイテンシ・低消費電力）。
  - 任意の Wake Word（例：「オーケーショータロウ」など）を設定可能。
  - Wake Word 検出時に以下を開始する。
    - ChatGPT Realtime API への WebSocket 接続。
    - マイクストリーミング（高音質モード）。
    - 無音検知（VAD）の起動。

### 3.2 STEP 2：ChatGPT Realtime API で会話開始

- 処理内容
  - ユーザーの音声を Realtime API にストリーミング送信。
  - Realtime API で音声認識＋応答生成。
  - 会話から「いつ・何をリマインドするか」を抽出し、Function Calling 用の JSON を生成する。

- 例（ユーザー発話）

  「明日の午後3時に、サムネ作業をリマインドして」

- 抽出される JSON の例

  ```json
  {
    "title": "サムネ作業",
    "datetime": "2025-11-16T15:00:00+09:00",
    "remind_before_minutes": 10
  }
````

- 運用前提
  - 2025年8月GAの `gpt-realtime` モデルを標準採用し、1セッション最大60分だが内部ロジックでは30分以内で再接続して安定稼働させる。
  - Realtime API の `turn_detection.server_vad` をデフォルトとし、ローカルVADはRaspberry Pi向けフォールバックとして維持する。

### 3.3 STEP 3：Google カレンダーへの予定登録

* 利用 API

  * Google Calendar API（Events.insert 等）

* 登録内容

  * summary: C（予定名、例：「サムネ作業」）
  * start / end:

    * start: A日のB時
    * end: 必要に応じてデフォルト 30 分後など固定値でもよい。
  * reminders:

    * 10分前通知（ユーザー指定に応じてカスタマイズも可）

### 3.4 STEP 4：リマインド時間の監視（常駐ロジック）

* Google Calendar API の Push Notification（`Events.watch` + Webhook）で予定変更を受信し、開始10分前以内のイベントを内部キューへ登録する。
* 外部公開エンドポイントを用意できない開発環境のみ、最短でも5分以上のポーリングで代替し、APIクォータ・レート制限を圧迫しないようにする。
* Webhookチャネルのリース期限を監視し、期限前に自動更新しつつ失効時には再登録をリトライする。
* 通知対象イベントがキューに入った場合

  * ChatGPT Realtime API を「通知用セッション」として再起動し、push通知内容をシステムメッセージとして渡す。
  * 音声読み上げ後も同じセッションを維持し、日時変更・キャンセルなどの追加リクエストを Function Calling で処理する。

### 3.5 STEP 5：音声によるリマインド通知とその後の会話

* 通知メッセージ例（システムメッセージ）

  「あと10分後に『サムネ作業』の予定があります」

* 通知後の挙動

  * 同じセッションを使って会話を継続できる。
  * ユーザーの音声コマンド例

    * 「開始時間を30分後にずらして」
    * 「この予定をキャンセルして」
  * これらの操作も Function Calling で JSON に変換し、Google カレンダーの予定を更新・削除する。

---

## 4. 無音検知・自動終了ロジック

### 4.1 目的

* 会話セッション中に「人間の発話がない状態」が一定時間続いた場合、

  * セッションを自動終了し、
  * Realtime API 接続とマイクストリーミングを停止して、リソース・電力消費を抑える。

* 背景ノイズや物音は発話とみなさず、無言時間判定に影響させない。

* v1 では Realtime API の `turn_detection.server_vad` を標準利用し、以降に記載するローカルVADは Raspberry Pi など回線不安定な環境でのフォールバックとして保持する。

### 4.2 音声検知方式（ローカルVADフォールバック）

* マイク入力を短いフレーム（10〜30ms 程度）に分割して処理。
* 各フレームごとに VAD（Voice Activity Detection）を行い、以下の2クラス判定を得る。

  * `speech`: 人間の音声らしいフレーム。
  * `noise`: それ以外の環境音・物音など。
* ロジック

  * `speech` フレームが検出された時のみ、`last_speech_time` を現在時刻に更新する。
  * `noise` フレームのみが続く場合、`last_speech_time` は更新されず、無言時間としてカウントされる。

### 4.3 セッションライフサイクルとタイムアウト

* Wake Word 検出後

  * Realtime API WebSocket 開始。
  * マイク入力ストリーム開始。
  * VAD による `speech` / `noise` 判定開始。

* セッション中に監視する項目

  * `last_speech_time`:

    * 直近で `speech` が検出された時刻。
  * `utterance_timeout_sec`（発話一区切り判定用）

    * 例: 5 秒
    * `現在時刻 - last_speech_time > utterance_timeout_sec` となった場合、

      * 「ユーザーの発話がひと区切りついた」とみなし、モデル側の応答生成を許可するなどに利用できる（必要に応じて）。
  * `session_timeout_sec`（セッション終了判定用）

    * 固定値: 10 秒
    * `現在時刻 - last_speech_time > session_timeout_sec` となった場合：

      * 会話セッション終了とみなす。
      * 実行する処理

        * Realtime API WebSocket を close。
        * マイクストリーミングを停止。
        * 状態を「Wake Word 待ち（Porcupineのみ常時稼働）」に戻す。

### 4.4 背景ノイズ・物音の扱い

* キーボードタイピング音、マウスクリック音、ドアの開閉音、物を置く音、エアコンや外の車の音など

  * 原則として VAD はこれらを `noise` と判定する前提。
* `noise` フレームのみが続いても `last_speech_time` は更新されないため、

  * 無言時間として扱われ、
  * セッションはタイムアウトに向かってカウントが進む。

### 4.5 他者の声・テレビ音声など

* テレビ・ラジオ・近くの他人の会話など、人間の声は `speech` と判定される可能性がある。
* v1 の方針

  * ユーザー本人以外の声が混ざることでセッションが長めに継続してしまう可能性は許容する。
  * 問題が大きくなった場合に、将来的に話者認識（speaker diarization）や「Wake Word 多段確認」などを検討する。

### 4.6 無音タイムアウトのパラメータ

* `utterance_timeout_sec`: 5秒（発話一区切りの目安）
* `session_timeout_sec`: 10秒（完全終了を判断する無言時間）
* 実装・テスト後の UX を見ながら、5〜15秒の範囲で微調整する想定。

### 4.7 省エネ設計の前提

* 常時稼働状態：

  * Porcupine のみを起動し、Wake Word 検出専用の軽い監視状態にする。
* 会話セッション中のみ：

  * Realtime API 接続、マイクストリーミング、VAD 処理を有効化。
* 無言タイムアウト（10 秒）でセッション終了：

  * Realtime API とマイク処理を停止し、再び Porcupine のみの待機状態へ戻る。
* これにより、

  * 「いつでも呼びかけられる」体験と、
  * 無駄な負荷をかけない運用の両立を狙う。

---

## 5. ターゲットデバイスとハードウェア要件

### 5.1 ターゲットデバイス

* 本番運用

  * Raspberry Pi 4 または Raspberry Pi 5
  * OS: Raspberry Pi OS（Debian系）
* 開発・検証

  * Mac / PC 上で同じコードを動かし、その後 Raspberry Pi に移行する。
  * コードは共通、設定だけ環境に応じて切り替える。

### 5.2 電源・給電方式

* 基本方針（本番）

  * 公式または同等クラスの USB-C 電源を使用する。
  * Raspberry Pi 4: 5V / 3A クラス
  * Raspberry Pi 5: 5V / 5A クラス（27W）
* モバイルバッテリー運用（オプション）

  * 条件

    * 5V 出力で 3A 程度を安定供給できる。
    * 低電流時に自動で電源 OFF にならない。
  * 用途

    * デモ・短時間の持ち運び用。
    * 24時間運用の本番では、基本的にコンセント給電を使用する。
* PC の USB ポートからの給電

  * 多くは 5V / 0.5〜0.9A 程度で、Raspberry Pi 4/5 を安定稼働させるには不足。
  * 電圧降下・低電圧警告・不安定動作の原因となるため非推奨。

### 5.3 オーディオ入出力（マイク・スピーカー）

* マイク（入力）

  * v1 の正式構成：外付け USB マイク

    * 一般的な USB コンデンサマイク
    * 会議用 USB スピーカーフォン（マイク＋スピーカー一体）も可
  * 条件

    * Raspberry Pi OS 上で ALSA / PulseAudio 等から録音デバイスとして認識できること。
* スピーカー（出力）

  * 優先構成

    * USB 給電式アナログスピーカー（3.5mm接続）
    * または USB オーディオデバイス一体型スピーカー
  * 条件

    * 標準のオーディオ出力として利用可能であること。
* Bluetooth オーディオ

  * Raspberry Pi 内蔵 Bluetooth により、Bluetooth スピーカーやヘッドホン（例：AirPods Pro）も利用可能。
  * 開発・検証フェーズでは利用してよい。
  * 本番構成としては、接続安定性・レイテンシの観点から「USBマイク＋有線スピーカー」を正式サポートとする。

### 5.4 Wake Wordライセンス前提

* Picovoice Porcupine の利用には Picovoice Console で取得する AccessKey が必須であり、実行バイナリに埋め込む際は安全に保管・ローテーションできる仕組みを用意する。
* 現時点では量産予定がなく個人ユース想定のため、Free Tier（非商用・月間アクティブユーザー1件まで）で運用し、端末ごとに AccessKey を払い出す。
* 将来的にデバイス数やエンドユーザー数を拡大する場合は Foundation 以上の商用プランへ切り替え、キーの配布・失効ルールを RUNBOOK にまとめる。

---

## 6. 開発フロー（Mac 開発 → Raspberry Pi 実行）

### 6.1 方針

* コードベースは Mac / Raspberry Pi 共通。
* 環境差は以下に閉じ込める。

  * 設定ファイル（`config/base.yaml`, `config/pc.dev.yaml`, `config/rpi.prod.yaml`）
  * 環境変数（`.env` の `APP_ENV` 等）

### 6.2 プロジェクト構成例

```text
wake-gpt-gcal-assistant/
├─ src/
│   ├─ main.py                  # エントリーポイント（Mac / RPi 共通）
│   ├─ wakeword/
│   │   ├─ __init__.py
│   │   └─ porcupine_listener.py # Wake Word検知（Porcupine）
│   ├─ audio/
│   │   ├─ __init__.py
│   │   ├─ input_stream.py       # マイク入力制御（VAD前提）
│   │   └─ output_stream.py      # スピーカー出力制御
│   ├─ realtime/
│   │   ├─ __init__.py
│   │   └─ openai_realtime_client.py  # Realtime APIクライアント
│   ├─ calendar/
│   │   ├─ __init__.py
│   │   └─ google_calendar_client.py # GoogleカレンダーAPIラッパー
│   ├─ vad/
│   │   ├─ __init__.py
│   │   └─ vad_detector.py        # 無音検知ロジック
│   ├─ config/
│   │   ├─ __init__.py
│   │   └─ loader.py              # 設定ファイル・環境変数読み込み
│   └─ util/
│       ├─ __init__.py
│       └─ logging_utils.py       # ログ関連ユーティリティ
│
├─ config/
│   ├─ base.yaml                  # 共通設定
│   ├─ pc.dev.yaml                # Mac開発用（デバイス名等）
│   └─ rpi.prod.yaml              # RPi本番用（デバイス名等）
│
├─ .env.example                   # 環境変数のサンプル
├─ requirements.txt               # Python依存パッケージ
├─ README.md                      # プロジェクト概要
└─ RUNBOOK.md                     # 起動・運用手順メモ
```

### 6.3 設定ファイルの例

`config/base.yaml`（共通）

```yaml
audio:
  sample_rate: 16000
  channels: 1
timeouts:
  utterance_timeout_sec: 5
  session_timeout_sec: 10
realtime:
  model: gpt-realtime
  endpoint: wss://api.openai.com/v1/realtime
  max_session_minutes: 60
  refresh_threshold_minutes: 30
  server_vad_idle_timeout_sec: 10
calendar:
  reminder_minutes_default: 10
  notification_method: push
  polling_interval_fallback_min: 5
```

`config/pc.dev.yaml`（Mac用）

```yaml
audio:
  input_device: "Mac 内蔵マイク または AirPods Pro"
  output_device: "Mac 内蔵スピーカー または AirPods Pro"
logging:
  level: "DEBUG"
mode: "dev"
```

`config/rpi.prod.yaml`（Raspberry Pi用）

```yaml
audio:
  input_device: "USB Audio Device"
  output_device: "USB Speaker"
logging:
  level: "INFO"
mode: "prod"
```

`.env.example`

```dotenv
OPENAI_API_KEY=your_openai_api_key_here
GOOGLE_CLIENT_ID=your_google_client_id
GOOGLE_CLIENT_SECRET=your_google_client_secret
GOOGLE_REFRESH_TOKEN=your_refresh_token
APP_ENV=pc.dev  # pc.dev / rpi.prod など
```

※ `.env` は初期セットアップ用のテンプレートとし、実運用では OpenAI API Key や Google OAuth クレデンシャル／リフレッシュトークンを OS キーチェーンや Secrets Manager など暗号化ストアに保存する。

### 6.4 main.py のイメージ

```python
from config.loader import load_config
from wakeword.porcupine_listener import WakeWordListener
from realtime.openai_realtime_client import RealtimeSession
from calendar.google_calendar_client import GoogleCalendarClient
from vad.vad_detector import VADDetector
from audio.input_stream import AudioInputStream
from audio.output_stream import AudioOutputStream


def main():
    # base.yaml + 環境別 yaml（pc.dev.yaml / rpi.prod.yaml）を読み込み
    config = load_config()

    audio_in = AudioInputStream(config)
    audio_out = AudioOutputStream(config)
    vad = VADDetector(config)
    calendar_client = GoogleCalendarClient(config)
    wake = WakeWordListener(config)

    # Wake Word待ちループ
    while True:
        # PorcupineでWake Word検知（ブロッキング）
        wake.wait_for_wake_word()

        # Wake Word 検出 → Realtimeセッション開始
        with RealtimeSession(
            config,
            audio_in,
            audio_out,
            vad,
            calendar_client,
        ) as session:
            # 中で：
            # - マイクストリーム開始
            # - VADでspeech/noise判定＆last_speech_time更新
            # - 無言10秒で session_timeout → ループを抜ける
            session.run_conversation_loop()


if __name__ == "__main__":
    main()
```

### 6.5 開発〜移行ステップ

1. Mac でリポジトリ作成・Git 初期化。
2. Mac 上で Realtime API・カレンダー連携・VAD・Porcupine を使って、対話フローを実装・テスト。
3. GitHub などに push して、Raspberry Pi 上で `git clone`（または ZIP 展開）。
4. Raspberry Pi で `pip install -r requirements.txt` 実行。
5. `.env` を配置し、`APP_ENV=rpi.prod` に設定。
6. `config/rpi.prod.yaml` の `input_device` / `output_device` を実際のデバイス名に合わせて修正。
7. `python src/main.py` で Wake Word → 会話 → 無言10秒終了までを確認。
8. 安定したら `systemd` などで常時稼働サービス化する。

---

## 7. 技術的制約事項

### Realtime API

- モデルは `gpt-realtime` を利用し、1セッション60分上限・32kトークン上限を前提に内部では30分以内で再接続して安定稼働させる。
- `turn_detection.server_vad` を有効化し、`server_vad_idle_timeout_sec` を設定ファイルから変更できるようにして無音終了ポリシーを一元管理する。
- 想定課金は音声入力/出力それぞれ $32 / $64 per 1M token を基準とし、運用開始時に OpenAI Usage Limit を設定する。

### Google カレンダー

- 通知方式は Push Notification（`Events.watch` + Webhook）を標準とし、リース期限切れ前に更新するタスクを常駐させる。
- パブリックエンドポイントを用意できない環境では 5 分以上のポーリングを許可するが、クォータを圧迫しないようイベントフィルタと指数バックオフを導入する。
- Webhook/ポーリングどちらの経路も、通知を内部キューに流し込んだ上で10分前ロジックに渡す。

### コストと Usage Limit

- 個人利用を想定し、Realtime API + Google Calendar API で月額 $10〜50 のレンジに収まるようセッション数・通話時間をログ計測する。
- プロジェクト単位で Usage Limit を OpenAI ダッシュボードに設定し、上限到達時は自動的にセッションを停止して通知する。

### Porcupine / Wake Word

- Picovoice AccessKey は端末ごとに払い出し、Free Tier（非商用・月間アクティブユーザー1）での運用を前提とする（量産予定なし）。
- デバイス数を拡張する場合は Foundation 以上のライセンスを取得し、キー配布・失効手順を RUNBOOK に追記する。

### セキュリティ・シークレット管理

- OpenAI API Key や Google OAuth クレデンシャル／リフレッシュトークンは OS キーチェーンや Secrets Manager に暗号化して保存し、`.env` には格納しない。
- Google の仕様上リフレッシュトークンはクライアント×ユーザーで最大100本のため、端末の追加・廃止時は手順化したローテーションを必須とする。

### ハードウェア・電源

- 推奨構成は Raspberry Pi 5 + 5V/5A USB-C PD、最小構成は Raspberry Pi 4 + 5V/3A。
- モバイルバッテリーでのデモ利用時は 5V/3A を安定供給でき、低電流カットのないモデルを選定する。

---

## 8. 実現可否のまとめ

* Wake Word 起動

  * Porcupine で任意のキーワードを検出できるため実現可能。
* ChatGPT Realtime API による音声対話

  * 標準機能としてサポートされており実現可能。
* 会話からの予定抽出（自然言語 → JSON）

  * Function Calling / ツール呼び出しで実現可能。
* Google カレンダーへの予定登録・更新・削除

  * Google Calendar API で実現可能。
* 予定時間前の音声通知

  * Push通知＋フォールバックポーリング＋Realtime API で実現可能。
* 無言10秒でのセッション自動終了

  * VAD ＋タイムアウト制御で実装可能。
* Mac 開発 → Raspberry Pi 移行

  * Python＋設定ファイル分離により、同一コードベースでの運用が可能。
